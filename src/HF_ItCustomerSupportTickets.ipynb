{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead4bcb-e50c-4c12-85d7-f780065d807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers datasets evaluate accelerate scikit-learn langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e672d-4aef-446b-9488-454ff7c0959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cust_tickets = load_dataset('Tobi-Bueck/customer-support-tickets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb602a2-98da-43ba-be1a-1f259cd50d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_tickets_df = cust_tickets['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f25f012-9a16-4856-8504-951643e5c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cust_tickets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c58d59-aec1-410f-b815-60e15ac289b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cust_tickets_df[cust_tickets_df['language'] == 'en'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe5106-f3f0-403d-a065-424f983d7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_sub = cust_tickets_df[['body', 'type', 'language']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07248cf-fbd1-497c-9a0f-d065da3f72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cust_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f50615-b317-43f6-be61-9f2636581d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cust_sub.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfee5f0-1c49-40b5-8e30-961b0abd5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_sub = cust_sub.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1855e-4813-4c05-b4ee-f247703111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect_langs\n",
    "\n",
    "languages = []\n",
    "\n",
    "# Loop over the rows of the DataFrame and append\n",
    "for row in range(len(cust_sub)):\n",
    "    languages.append(detect_langs(cust_sub.iloc[row, 0]))\n",
    "\n",
    "# Clean the list by splitting\n",
    "languages = [str(lang).split(':')[0][1:] for lang in languages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a78a5d-92ef-4905-86a2-8f4e23ee925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39803e9d-3572-4739-bb6f-1cb79faa0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(languages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d45a3c-a68f-4c2b-99b2-49485b2bff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(languages)\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7cd72-ba54-43b6-b1db-58c9bb1722e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_sub['language'] = languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baf17b1-cfb8-4fc6-b782-c5ea2725ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cust_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f0769-204c-4b19-8cd0-48be0ebdd7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_en = cust_sub[cust_sub['language'] == 'en'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560fccf-b685-45b8-861a-86f2576fbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cust_en.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833fd817-06e3-4465-a0e7-2c9eb4ab89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cust_en.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c897a08-c6f9-4b72-bb42-ef648d91d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "cust_en['label'] = label_encoder.fit_transform(cust_en['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3d1b8-8257-45b8-86f5-2db3850451e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1563ff0-df7f-4867-a102-a20e8f98d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_en.rename(columns={'body': 'text'}, inplace=True)\n",
    "cust_en_set = cust_en[['text', 'label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd16669-a578-4376-ab2c-e44b65058f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cust_en_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cad6b2-009c-4b4c-a97d-2cfbe1a302f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert pandas DataFrame to Hugging Face Dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "hf_cust = Dataset.from_pandas(cust_en_set)\n",
    "\n",
    "# Split into train and test sets\n",
    "hf_cust = hf_cust.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63724590-0f54-411a-9b59-a49e8aacc606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c39af-b3aa-44d4-91f1-6917f222d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cd8cd-6a0c-4bc6-b3b0-d380e59b738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing function over the entire dataset, we use map function\n",
    "tokenized_cust = hf_cust.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a6fe7-786d-4abe-aae2-be95ba85c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fcf92-686d-455b-b599-8f129d1021c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c725b1af-2886-4fd1-bf29-dcc0a2a2baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that passes predictions and labels to compute to calculate accuracy\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60405f-e021-4777-a5c2-779a57915719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - create a map of expected ids to their labels with label2id and id2label\n",
    "label2id = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d932fee-84e9-4505-9d6f-827001e52a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert/distilbert-base-uncased', num_labels=4, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57afa996-0430-4b18-a931-dcf9b40809a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_cust['train'].shape)\n",
    "print(tokenized_cust['test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde76f38-a866-4d60-aa38-e6e049045d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training hyperparameters, pass training arguments to trainer, and call train() to finetune the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_cust['train'],\n",
    "    eval_dataset=tokenized_cust['test'],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bddc1-b217-4bb8-a649-a69a2da7a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Inference\n",
    "import torch\n",
    "text = \"User cannot connect to VPN\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "pred = logits.argmax(dim=1).item()\n",
    "print('Predicted label:', model.config.id2label[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485c18b-2863-4fea-9fc8-16618c5d4217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
